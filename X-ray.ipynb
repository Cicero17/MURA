{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from csv import reader\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
    "from tensorflow.keras import models, layers, backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(source, kind, reshape, standardize):\n",
    "    train_imgs, train_vals = extract_helper(source, 'train', kind, reshape)\n",
    "    test_imgs, test_vals = extract_helper(source, 'valid', kind, reshape)\n",
    "    if standardize == True:\n",
    "        mean = get_mean(data_x)\n",
    "        std = get_std(data_x)\n",
    "        train_imgs = (train_imgs - mean)/std\n",
    "        test_imgs = (test_imgs - mean)/std\n",
    "    return train_imgs, train_vals, test_imgs, test_vals\n",
    "\n",
    "def get_mean(data_x):\n",
    "    shape = data_x.shape\n",
    "    mean = np.zeros((shape[1], shape[2]))\n",
    "    for i in range(shape[0]):\n",
    "        for j in range(shape[1]):\n",
    "            for k in range(shape[2]):\n",
    "                mean[j][k] += data_x[i][j][k][0]\n",
    "    mean/= len(data_x)\n",
    "    return mean\n",
    "\n",
    "def get_std(data_x):\n",
    "    shape = data_x.shape\n",
    "    std = np.zeros((shape[1], shape[2]))\n",
    "    for j in range(shape[1]):\n",
    "        for k in range(shape[2]):\n",
    "            aux = np.array([data_x[i][j][k][0] for i in range(shape[0])])\n",
    "            std[j][k] = np.std(aux)\n",
    "    return std\n",
    "\n",
    "\n",
    "def extract_all_data(source, reshape, standardize):\n",
    "    train_imgs, train_vals = extract_all_helper(source, 'train', reshape)\n",
    "    test_imgs, test_vals = extract_all_helper(source, 'valid', reshape)\n",
    "    if standardize == True:\n",
    "        mean = get_mean(data_x)\n",
    "        std = get_std(data_x)\n",
    "        train_imgs = (train_imgs - mean)/std\n",
    "        test_imgs = (test_imgs - mean)/std\n",
    "    return train_imgs, train_vals, test_imgs, test_vals\n",
    "\n",
    "def extract_helper(source, torv, kind, reshape):\n",
    "    os.chdir(source+'\\\\MURA-v1.1')\n",
    "    os.chdir(torv+'_specific_paths')\n",
    "    file = open(torv+'_image_paths_'+kind+'.csv')\n",
    "    return extract(source, file, reshape)\n",
    "\n",
    "def extract_all_helper(source, torv, reshape):\n",
    "    os.chdir(source+'\\\\MURA-v1.1')\n",
    "    file = open(torv+'_image_paths.csv')\n",
    "    return extract(source, file, reshape)\n",
    "    \n",
    "def extract(source, file, reshape):\n",
    "    readCSV = reader(file)\n",
    "    imgs = []\n",
    "    vals = []\n",
    "    for row in readCSV:\n",
    "        im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "        imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "        if 'positive' in row[0]:\n",
    "            vals.append(1)\n",
    "        else:\n",
    "            vals.append(0)\n",
    "    file.close()\n",
    "    imgs = np.array(imgs)\n",
    "    vals = np.array(vals)\n",
    "    imgs = np.expand_dims(imgs, axis = 3)\n",
    "    return imgs,vals\n",
    "\n",
    "class patient:\n",
    "    def __init__(self, imgs, vals, value):\n",
    "        self.imgs = imgs\n",
    "        self.vals = vals\n",
    "        self.value = value\n",
    "        \n",
    "def patient_code(path):\n",
    "    pos = path.find('patient')+7\n",
    "    return path[pos:pos+5]\n",
    "\n",
    "def patient_value(path):\n",
    "    if 'positive' in path:\n",
    "        return 1\n",
    "    return 0\n",
    "        \n",
    "def extract_data_patients(source, kind, reshape, standardize):\n",
    "    train_patients = extract_helper_patients(source, 'train', kind, reshape)\n",
    "    test_patients  = extract_helper_patients(source, 'valid',  kind, reshape)\n",
    "    if standardize == True:\n",
    "        train_imgs = np.array([])\n",
    "        for p in train_patients:\n",
    "            train_imgs = np.concatenate(train_imgs, p.imgs)\n",
    "        mean = get_mean(data_x)\n",
    "        std = get_std(data_x)\n",
    "        for p in train_patients:\n",
    "            p.imgs = (p.imgs - mean)/std\n",
    "        for p in test_patients:\n",
    "            p.imgs = (p.imgs - mean)/std\n",
    "    return train_patients, test_patients\n",
    "    \n",
    "def extract_helper_patients(source, torv, kind, reshape):\n",
    "    os.chdir(source+'\\\\MURA-v1.1')\n",
    "    os.chdir(torv+'_specific_paths')\n",
    "    file = open(torv+'_image_paths_'+kind+'.csv')\n",
    "    return extract_patients(source, file, reshape)\n",
    "\n",
    "def extract_patients(source, file, reshape):\n",
    "    patients = []\n",
    "    readCSV = reader(file)\n",
    "    imgs = []\n",
    "    vals = []\n",
    "    \n",
    "    row = next(readCSV)\n",
    "    prev_patient = patient_code(row[0])\n",
    "    vals.append(patient_value(row[0]))\n",
    "    im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "    imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "    \n",
    "    for row in readCSV:\n",
    "        curr_patient = patient_code(row[0])\n",
    "        if curr_patient == prev_patient:\n",
    "            vals.append(patient_value(row[0]))\n",
    "            im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "            imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "                \n",
    "        else:\n",
    "            imgs = np.array(imgs)\n",
    "            imgs = np.expand_dims(imgs, axis=3)\n",
    "            vals = np.array(vals)\n",
    "            patients.append(patient(imgs, vals, vals[0]))\n",
    "            imgs = []\n",
    "            vals = []\n",
    "            prev_patient = curr_patient\n",
    "            vals.append(patient_value(row[0]))\n",
    "            im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "            imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "                \n",
    "    file.close()\n",
    "    imgs = np.array(imgs)\n",
    "    imgs = np.expand_dims(imgs, axis=3)\n",
    "    vals = np.array(vals)\n",
    "    patients.append(patient(imgs, vals, vals[0])) \n",
    "\n",
    "    return patients  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_validation(model, data_x, data_y, batch_size, number_of_epochs, class_weights, proportion = 0.8):\n",
    "    proportion = int(len(data_y)*proportion)\n",
    "    train_x, train_y = shuffler(data_x[:proportion], data_y[:proportion])\n",
    "    valid_x, valid_y = shuffler(data_x[proportion:], data_y[proportion:])\n",
    "    score = 0\n",
    "    if class_weights == True:\n",
    "        model_copy = copy_model(model)\n",
    "        model_copy.fit(train_x, train_y, batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(train_y))\n",
    "        score = conf_matrix(model_copy, valid_x, valid_y)\n",
    "    else:\n",
    "        model.fit(train_x, train_y, batch_size = batch_size, epochs = number_of_epochs)\n",
    "        score = conf_matrix(model, valid_x, valid_y)\n",
    "    if class_weights == True:\n",
    "        model.fit(data_x, data_y, batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(data_y))\n",
    "    else:\n",
    "        model.fit(valid_x, valid_y, batch_size = batch_size, epochs = number_of_epochs)\n",
    "    return score, model\n",
    "\n",
    "def k_fold_cross_validation(k, model, data_x, data_y, batch_size, number_of_epochs, class_weights):\n",
    "    data_x, data_y = shuffler(data_x, data_y)\n",
    "    folds_x = []\n",
    "    folds_y = []\n",
    "    l = len(data_y)\n",
    "    for i in range(k):\n",
    "        folds_x.append(data_x[(l//k)*i: (l//k)*(i+1)])\n",
    "        folds_y.append(data_y[(l//k)*i: (l//k)*(i+1)])\n",
    "    score = 0\n",
    "    for i in range(k):\n",
    "        model_copy = copy_model(model)\n",
    "        for j in range(k):\n",
    "            if j!=i:\n",
    "                if class_weights == True:\n",
    "                    model_copy.fit(folds_x[j],folds_y[j], batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(folds_y[j]))\n",
    "                else:\n",
    "                    model_copy.fit(folds_x[j],folds_y[j], batch_size = batch_size, epochs = number_of_epochs)\n",
    "        score += model_copy.evaluate(folds_x[i],folds_y[i])[1]\n",
    "    \n",
    "    if class_weights == True:\n",
    "        model.fit(data_x, data_y, batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(data_y))\n",
    "    else:\n",
    "        model = model_copy\n",
    "        model.fit(folds_x[k-1],folds_y[k-1], batch_size = batch_size, epochs = number_of_epochs)\n",
    "    return score/k, model\n",
    "\n",
    "def shuffler(data_x, data_y):\n",
    "    p = np.random.permutation(len(data_y))\n",
    "    return (data_x[p], data_y[p])\n",
    "\n",
    "def conf_matrix(model, data_x, data_y): \n",
    "    y_pred = model.predict(data_x).flatten().tolist()\n",
    "    y_true = data_y.tolist()\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = round(y_pred[i])\n",
    "    return print_conf_matrix(y_true, y_pred)\n",
    "\n",
    "def patients_conf_matrix(model, test_patients): \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for p in test_patients:\n",
    "        y_true.append(p.value)\n",
    "        p_predict = round(np.mean(model.predict(p.imgs)))\n",
    "        y_pred.append(p_predict)\n",
    "    return print_conf_matrix(y_true, y_pred)\n",
    "    \n",
    "def print_conf_matrix(y_true, y_pred):\n",
    "    score = 0\n",
    "    tn, fp, fn, tp = 0, 0, 0, 0\n",
    "    l = len(y_true)\n",
    "    for i in range(l):\n",
    "        if y_pred[i] == 0 and y_true[i] == 0:\n",
    "            tn+= 1\n",
    "            score+= 1\n",
    "        elif y_pred[i] == 1 and y_true[i] == 0:\n",
    "            fp+= 1\n",
    "        elif y_pred[i] == 0 and y_true[i] == 1:\n",
    "            fn+= 1\n",
    "        else:\n",
    "            tp+= 1\n",
    "            score+= 1\n",
    "    score/= l\n",
    "    print('Accuracy: '+str(score))\n",
    "    print('     T       F')\n",
    "    print('P    '+str(tp)+' '*(8-len(str(tp)))+str(fp))\n",
    "    print('N    '+str(tn)+' '*(8-len(str(tn)))+str(fn))\n",
    "    return score\n",
    "\n",
    "def save_model(source, model, model_name):\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\models')\n",
    "    model.save(model_name+'.h5')\n",
    "    \n",
    "def load_model(source, model_name):\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\models')\n",
    "    return models.load_model(model_name+'.h5')\n",
    "\n",
    "def copy_model(model):\n",
    "    model_copy = models.clone_model(model)\n",
    "    model_copy.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model_copy\n",
    "\n",
    "def class_weight(data_y):\n",
    "    positive = np.sum(data_y)\n",
    "    negative = np.size(data_y) - positive\n",
    "    return {0 : 1 + positive/negative, 1: 1 + negative/positive}\n",
    "\n",
    "def heatmaps(source, kind, reshape, model, last_conv_index, model_name = None, mean = None, std =  None): \n",
    "    image_folder_path = source+'\\\\MURA-v1.1\\\\heatmaps\\\\' + kind + '\\\\images'\n",
    "    for image_name in os.listdir(image_folder_path):\n",
    "        heatmap(source, image_name, kind, reshape, model, last_conv_index, model_name, mean, std)\n",
    "\n",
    "def heatmap(source, image_name, kind, reshape, model, last_conv_index, model_name = None, mean = None, std =  None): # image_name must include extension .png\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\heatmaps\\\\'+kind+'\\\\images')\n",
    "    image = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, reshape)\n",
    "    image = np.expand_dims(image, axis = 2)\n",
    "    if (mean, std) != (None, None):\n",
    "        image = (image - mean)/std\n",
    "    pred = round(model.predict(np.array([image])).flatten().tolist()[0])\n",
    "    print('\\''+image_name+'\\''+' predicted to be ', end = '')\n",
    "    if pred == 0:\n",
    "        print('negative')\n",
    "    else:\n",
    "        print('positive')\n",
    "\n",
    "    model_output = model.output\n",
    "    conv_layer = model.get_layer(index = last_conv_index) # indexed from 0\n",
    "    grads = K.gradients(model_output, conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, conv_layer.output[0]])\n",
    "    pooled_grads_val, conv_layer_output_val = iterate(np.array([image]))\n",
    "    for i in range(conv_layer_output_val.shape[2]):\n",
    "        conv_layer_output_val[:, :, i]*= pooled_grads_val[i]\n",
    "    \n",
    "    heatmap = np.mean(conv_layer_output_val, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap/= np.max(heatmap)\n",
    "    image = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap_applied = heatmap * 0.5 + image\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\heatmaps\\\\'+kind+'\\\\heatmaps')\n",
    "    image_name = image_name[:-4]\n",
    "    if model_name != None:\n",
    "        cv2.imwrite(model_name +'_'+ image_name +'_heatmap.png', heatmap)\n",
    "        cv2.imwrite(model_name +'_'+ image_name +'_heatmap_applied.png', heatmap_applied)\n",
    "    else:\n",
    "        cv2.imwrite(image_name + 'heatmap.png', heatmap)\n",
    "        cv2.imwrite(image_name + '_heatmap_applied.png', heatmap_applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'C:\\\\Users\\\\Admin\\\\Desktop\\\\python' # depends on where you saved MURA\n",
    "reshape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: how to extract data\n",
    "train_x, train_y, test_x, test_y = extract_data(source ,'hand', reshape, True)\n",
    "train_x, train_y = shuffler(train_x, train_y)\n",
    "test_x, test_y = shuffler(test_x, test_y)\n",
    "train_patients, test_patients = extract_data_patients(source ,'hand', reshape, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), activation='relu', input_shape=(224,224,1), padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(4, (5, 5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(4, (5, 5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(8, (7, 7), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "save_model(model, source, 'conv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5543/5543 [==============================] - 67s 12ms/sample - loss: 0.7625 - acc: 0.5703\n",
      "Epoch 2/15\n",
      "5543/5543 [==============================] - 69s 12ms/sample - loss: 0.6893 - acc: 0.6652s - l\n",
      "Epoch 3/15\n",
      "5543/5543 [==============================] - 70s 13ms/sample - loss: 0.6896 - acc: 0.7023\n",
      "Epoch 4/15\n",
      "5543/5543 [==============================] - 75s 14ms/sample - loss: 0.6884 - acc: 0.6982\n",
      "Epoch 5/15\n",
      "5543/5543 [==============================] - 74s 13ms/sample - loss: 0.6864 - acc: 0.6904\n",
      "Epoch 6/15\n",
      "5543/5543 [==============================] - 82s 15ms/sample - loss: 0.6860 - acc: 0.6957\n",
      "Epoch 7/15\n",
      "5543/5543 [==============================] - 76s 14ms/sample - loss: 0.6846 - acc: 0.6807\n",
      "Epoch 8/15\n",
      "5543/5543 [==============================] - 76s 14ms/sample - loss: 0.6837 - acc: 0.6969\n",
      "Epoch 9/15\n",
      "5543/5543 [==============================] - 81s 15ms/sample - loss: 0.6820 - acc: 0.6874\n",
      "Epoch 10/15\n",
      "5543/5543 [==============================] - 79s 14ms/sample - loss: 0.6796 - acc: 0.6870\n",
      "Epoch 11/15\n",
      "5543/5543 [==============================] - 68s 12ms/sample - loss: 0.6801 - acc: 0.6807\n",
      "Epoch 12/15\n",
      "5543/5543 [==============================] - 65s 12ms/sample - loss: 0.6792 - acc: 0.6810\n",
      "Epoch 13/15\n",
      "5543/5543 [==============================] - 65s 12ms/sample - loss: 0.6775 - acc: 0.6857\n",
      "Epoch 14/15\n",
      "5543/5543 [==============================] - 64s 12ms/sample - loss: 0.6763 - acc: 0.6518\n",
      "Epoch 15/15\n",
      "5543/5543 [==============================] - 67s 12ms/sample - loss: 0.6767 - acc: 0.6493\n",
      "Accuracy: 0.558695652173913\n",
      "     T       F\n",
      "P    63      77\n",
      "N    194     126\n",
      "Accuracy: 0.5786163522012578\n",
      "     T       F\n",
      "P    23      24\n",
      "N    69      43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5786163522012578"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size = 8, epochs = 15, class_weight = class_weight(train_y))\n",
    "save_model(source, model, 'conv3_224_HAND')\n",
    "conf_matrix(model, test_x, test_y)\n",
    "patients_conf_matrix(model, test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_negative1.png' predicted to be negative\n",
      "'train_negative10.png' predicted to be negative\n",
      "'train_negative11.png' predicted to be negative\n",
      "'train_negative12.png' predicted to be negative\n",
      "'train_negative13.png' predicted to be negative\n",
      "'train_negative14.png' predicted to be negative\n",
      "'train_negative15.png' predicted to be negative\n",
      "'train_negative16.png' predicted to be negative\n",
      "'train_negative17.png' predicted to be negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:135: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_negative18.png' predicted to be negative\n",
      "'train_negative19.png' predicted to be positive\n",
      "'train_negative2.png' predicted to be positive\n",
      "'train_negative20.png' predicted to be positive\n",
      "'train_negative21.png' predicted to be positive\n",
      "'train_negative22.png' predicted to be positive\n",
      "'train_negative23.png' predicted to be positive\n",
      "'train_negative24.png' predicted to be negative\n",
      "'train_negative25.png' predicted to be negative\n",
      "'train_negative26.png' predicted to be positive\n",
      "'train_negative27.png' predicted to be negative\n",
      "'train_negative28.png' predicted to be positive\n",
      "'train_negative29.png' predicted to be positive\n",
      "'train_negative3.png' predicted to be negative\n",
      "'train_negative30.png' predicted to be negative\n",
      "'train_negative4.png' predicted to be negative\n",
      "'train_negative5.png' predicted to be negative\n",
      "'train_negative6.png' predicted to be negative\n",
      "'train_negative7.png' predicted to be negative\n",
      "'train_negative8.png' predicted to be negative\n",
      "'train_negative9.png' predicted to be negative\n",
      "'train_positive1.png' predicted to be negative\n",
      "'train_positive10.png' predicted to be positive\n",
      "'train_positive100.png' predicted to be positive\n",
      "'train_positive11.png' predicted to be negative\n",
      "'train_positive12.png' predicted to be positive\n",
      "'train_positive13.png' predicted to be negative\n",
      "'train_positive14.png' predicted to be positive\n",
      "'train_positive15.png' predicted to be positive\n",
      "'train_positive16.png' predicted to be negative\n",
      "'train_positive17.png' predicted to be positive\n",
      "'train_positive18.png' predicted to be positive\n",
      "'train_positive19.png' predicted to be negative\n",
      "'train_positive2.png' predicted to be negative\n",
      "'train_positive20.png' predicted to be negative\n",
      "'train_positive21.png' predicted to be positive\n",
      "'train_positive22.png' predicted to be negative\n",
      "'train_positive23.png' predicted to be positive\n",
      "'train_positive24.png' predicted to be positive\n",
      "'train_positive25.png' predicted to be negative\n",
      "'train_positive26.png' predicted to be negative\n",
      "'train_positive27.png' predicted to be negative\n",
      "'train_positive28.png' predicted to be positive\n",
      "'train_positive29.png' predicted to be positive\n",
      "'train_positive3.png' predicted to be negative\n",
      "'train_positive30.png' predicted to be positive\n",
      "'train_positive31.png' predicted to be negative\n",
      "'train_positive32.png' predicted to be negative\n",
      "'train_positive33.png' predicted to be negative\n",
      "'train_positive34.png' predicted to be positive\n",
      "'train_positive35.png' predicted to be negative\n",
      "'train_positive36.png' predicted to be positive\n",
      "'train_positive37.png' predicted to be positive\n",
      "'train_positive38.png' predicted to be negative\n",
      "'train_positive39.png' predicted to be positive\n",
      "'train_positive4.png' predicted to be positive\n",
      "'train_positive40.png' predicted to be negative\n",
      "'train_positive41.png' predicted to be positive\n",
      "'train_positive42.png' predicted to be negative\n",
      "'train_positive43.png' predicted to be negative\n",
      "'train_positive44.png' predicted to be negative\n",
      "'train_positive45.png' predicted to be negative\n",
      "'train_positive46.png' predicted to be positive\n",
      "'train_positive47.png' predicted to be negative\n",
      "'train_positive48.png' predicted to be negative\n",
      "'train_positive49.png' predicted to be positive\n",
      "'train_positive5.png' predicted to be positive\n",
      "'train_positive50.png' predicted to be negative\n",
      "'train_positive51.png' predicted to be negative\n",
      "'train_positive52.png' predicted to be positive\n",
      "'train_positive53.png' predicted to be negative\n",
      "'train_positive54.png' predicted to be negative\n",
      "'train_positive55.png' predicted to be positive\n",
      "'train_positive56.png' predicted to be negative\n",
      "'train_positive57.png' predicted to be positive\n",
      "'train_positive58.png' predicted to be negative\n",
      "'train_positive59.png' predicted to be positive\n",
      "'train_positive6.png' predicted to be negative\n",
      "'train_positive60.png' predicted to be positive\n",
      "'train_positive61.png' predicted to be negative\n",
      "'train_positive62.png' predicted to be positive\n",
      "'train_positive63.png' predicted to be positive\n",
      "'train_positive64.png' predicted to be positive\n",
      "'train_positive65.png' predicted to be positive\n",
      "'train_positive66.png' predicted to be positive\n",
      "'train_positive67.png' predicted to be positive\n",
      "'train_positive68.png' predicted to be positive\n",
      "'train_positive69.png' predicted to be positive\n",
      "'train_positive7.png' predicted to be negative\n",
      "'train_positive70.png' predicted to be positive\n",
      "'train_positive71.png' predicted to be negative\n",
      "'train_positive72.png' predicted to be positive\n",
      "'train_positive73.png' predicted to be positive\n",
      "'train_positive74.png' predicted to be negative\n",
      "'train_positive75.png' predicted to be positive\n",
      "'train_positive76.png' predicted to be negative\n",
      "'train_positive77.png' predicted to be positive\n",
      "'train_positive78.png' predicted to be negative\n",
      "'train_positive79.png' predicted to be negative\n",
      "'train_positive8.png' predicted to be positive\n",
      "'train_positive80.png' predicted to be negative\n",
      "'train_positive81.png' predicted to be positive\n",
      "'train_positive82.png' predicted to be positive\n",
      "'train_positive83.png' predicted to be positive\n",
      "'train_positive84.png' predicted to be negative\n",
      "'train_positive85.png' predicted to be positive\n",
      "'train_positive86.png' predicted to be positive\n",
      "'train_positive87.png' predicted to be positive\n",
      "'train_positive88.png' predicted to be negative\n",
      "'train_positive89.png' predicted to be negative\n",
      "'train_positive9.png' predicted to be positive\n",
      "'train_positive90.png' predicted to be positive\n",
      "'train_positive91.png' predicted to be negative\n",
      "'train_positive92.png' predicted to be negative\n",
      "'train_positive93.png' predicted to be positive\n",
      "'train_positive94.png' predicted to be positive\n",
      "'train_positive95.png' predicted to be negative\n",
      "'train_positive96.png' predicted to be positive\n",
      "'train_positive97.png' predicted to be positive\n",
      "'train_positive98.png' predicted to be negative\n",
      "'train_positive99.png' predicted to be positive\n",
      "'valid_negative1.png' predicted to be negative\n",
      "'valid_negative10.png' predicted to be negative\n",
      "'valid_negative11.png' predicted to be negative\n",
      "'valid_negative12.png' predicted to be negative\n",
      "'valid_negative13.png' predicted to be negative\n",
      "'valid_negative14.png' predicted to be negative\n",
      "'valid_negative15.png' predicted to be negative\n",
      "'valid_negative16.png' predicted to be negative\n",
      "'valid_negative17.png' predicted to be negative\n",
      "'valid_negative18.png' predicted to be negative\n",
      "'valid_negative19.png' predicted to be negative\n",
      "'valid_negative2.png' predicted to be negative\n",
      "'valid_negative20.png' predicted to be positive\n",
      "'valid_negative21.png' predicted to be negative\n",
      "'valid_negative22.png' predicted to be positive\n",
      "'valid_negative23.png' predicted to be positive\n",
      "'valid_negative24.png' predicted to be positive\n",
      "'valid_negative25.png' predicted to be positive\n",
      "'valid_negative26.png' predicted to be negative\n",
      "'valid_negative27.png' predicted to be negative\n",
      "'valid_negative28.png' predicted to be negative\n",
      "'valid_negative29.png' predicted to be negative\n",
      "'valid_negative3.png' predicted to be negative\n",
      "'valid_negative30.png' predicted to be negative\n",
      "'valid_negative4.png' predicted to be positive\n",
      "'valid_negative5.png' predicted to be negative\n",
      "'valid_negative6.png' predicted to be negative\n",
      "'valid_negative7.png' predicted to be negative\n",
      "'valid_negative8.png' predicted to be negative\n",
      "'valid_negative9.png' predicted to be positive\n",
      "'valid_positive1.png' predicted to be negative\n",
      "'valid_positive10.png' predicted to be negative\n",
      "'valid_positive100.png' predicted to be positive\n",
      "'valid_positive11.png' predicted to be negative\n",
      "'valid_positive12.png' predicted to be negative\n",
      "'valid_positive13.png' predicted to be negative\n",
      "'valid_positive14.png' predicted to be negative\n",
      "'valid_positive15.png' predicted to be negative\n",
      "'valid_positive16.png' predicted to be negative\n",
      "'valid_positive17.png' predicted to be negative\n",
      "'valid_positive18.png' predicted to be negative\n",
      "'valid_positive19.png' predicted to be positive\n",
      "'valid_positive2.png' predicted to be negative\n",
      "'valid_positive20.png' predicted to be negative\n",
      "'valid_positive21.png' predicted to be negative\n",
      "'valid_positive22.png' predicted to be negative\n",
      "'valid_positive23.png' predicted to be negative\n",
      "'valid_positive24.png' predicted to be negative\n",
      "'valid_positive25.png' predicted to be negative\n",
      "'valid_positive26.png' predicted to be negative\n",
      "'valid_positive27.png' predicted to be negative\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'valid_positive28.png' predicted to be positive\n",
      "'valid_positive29.png' predicted to be positive\n",
      "'valid_positive3.png' predicted to be negative\n",
      "'valid_positive30.png' predicted to be positive\n",
      "'valid_positive31.png' predicted to be positive\n",
      "'valid_positive32.png' predicted to be negative\n",
      "'valid_positive33.png' predicted to be negative\n",
      "'valid_positive34.png' predicted to be negative\n",
      "'valid_positive35.png' predicted to be positive\n",
      "'valid_positive36.png' predicted to be negative\n",
      "'valid_positive37.png' predicted to be negative\n",
      "'valid_positive38.png' predicted to be negative\n",
      "'valid_positive39.png' predicted to be negative\n",
      "'valid_positive4.png' predicted to be positive\n",
      "'valid_positive40.png' predicted to be positive\n",
      "'valid_positive41.png' predicted to be negative\n",
      "'valid_positive42.png' predicted to be negative\n",
      "'valid_positive43.png' predicted to be negative\n",
      "'valid_positive44.png' predicted to be negative\n",
      "'valid_positive45.png' predicted to be positive\n",
      "'valid_positive46.png' predicted to be negative\n",
      "'valid_positive47.png' predicted to be negative\n",
      "'valid_positive48.png' predicted to be negative\n",
      "'valid_positive49.png' predicted to be positive\n",
      "'valid_positive5.png' predicted to be negative\n",
      "'valid_positive50.png' predicted to be positive\n",
      "'valid_positive51.png' predicted to be negative\n",
      "'valid_positive52.png' predicted to be positive\n",
      "'valid_positive53.png' predicted to be negative\n",
      "'valid_positive54.png' predicted to be positive\n",
      "'valid_positive55.png' predicted to be negative\n",
      "'valid_positive56.png' predicted to be negative\n",
      "'valid_positive57.png' predicted to be positive\n",
      "'valid_positive58.png' predicted to be positive\n",
      "'valid_positive59.png' predicted to be positive\n",
      "'valid_positive6.png' predicted to be positive\n",
      "'valid_positive60.png' predicted to be negative\n",
      "'valid_positive61.png' predicted to be negative\n",
      "'valid_positive62.png' predicted to be negative\n",
      "'valid_positive63.png' predicted to be negative\n",
      "'valid_positive64.png' predicted to be negative\n",
      "'valid_positive65.png' predicted to be positive\n",
      "'valid_positive66.png' predicted to be positive\n",
      "'valid_positive67.png' predicted to be negative\n",
      "'valid_positive68.png' predicted to be negative\n",
      "'valid_positive69.png' predicted to be negative\n",
      "'valid_positive7.png' predicted to be positive\n",
      "'valid_positive70.png' predicted to be positive\n",
      "'valid_positive71.png' predicted to be negative\n",
      "'valid_positive72.png' predicted to be negative\n",
      "'valid_positive73.png' predicted to be positive\n",
      "'valid_positive74.png' predicted to be negative\n",
      "'valid_positive75.png' predicted to be positive\n",
      "'valid_positive76.png' predicted to be positive\n",
      "'valid_positive77.png' predicted to be negative\n",
      "'valid_positive78.png' predicted to be negative\n",
      "'valid_positive79.png' predicted to be negative\n",
      "'valid_positive8.png' predicted to be negative\n",
      "'valid_positive80.png' predicted to be positive\n",
      "'valid_positive81.png' predicted to be positive\n",
      "'valid_positive82.png' predicted to be negative\n",
      "'valid_positive83.png' predicted to be negative\n",
      "'valid_positive84.png' predicted to be negative\n",
      "'valid_positive85.png' predicted to be positive\n",
      "'valid_positive86.png' predicted to be negative\n",
      "'valid_positive87.png' predicted to be negative\n",
      "'valid_positive88.png' predicted to be negative\n",
      "'valid_positive89.png' predicted to be positive\n",
      "'valid_positive9.png' predicted to be positive\n",
      "'valid_positive90.png' predicted to be positive\n",
      "'valid_positive91.png' predicted to be negative\n",
      "'valid_positive92.png' predicted to be negative\n",
      "'valid_positive93.png' predicted to be positive\n",
      "'valid_positive94.png' predicted to be positive\n",
      "'valid_positive95.png' predicted to be negative\n",
      "'valid_positive96.png' predicted to be negative\n",
      "'valid_positive97.png' predicted to be negative\n",
      "'valid_positive98.png' predicted to be positive\n",
      "'valid_positive99.png' predicted to be negative\n"
     ]
    }
   ],
   "source": [
    "# Example: how to use models\n",
    "# model = load_model(source, 'conv3forearmdb224sgd')\n",
    "heatmaps(source, 'hand', (224,224), model, 13, 'conv3_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
