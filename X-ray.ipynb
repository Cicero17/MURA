{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os \n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from csv import reader\n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
    "from tensorflow.keras import models, layers, backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(source, kind, reshape, standardize):\n",
    "    train_imgs, train_vals = extract_helper(source, 'train', kind, reshape)\n",
    "    test_imgs, test_vals = extract_helper(source, 'valid', kind, reshape)\n",
    "    if standardize == True:\n",
    "        mean = get_mean(train_imgs)\n",
    "        std = get_std(train_imgs, mean)\n",
    "        train_imgs = (train_imgs - mean)/std\n",
    "        test_imgs = (test_imgs - mean)/std\n",
    "    return train_imgs, train_vals, test_imgs, test_vals\n",
    "\n",
    "def get_mean(data_x):\n",
    "    shape = data_x.shape\n",
    "    mean = np.zeros((shape[1], shape[2]))\n",
    "    for j in range(shape[1]):\n",
    "        for k in range(shape[2]):\n",
    "            aux = np.array([data_x[i][j][k][0] for i in range(shape[0])])\n",
    "            mean[j][k] = np.mean(aux)\n",
    "    return mean\n",
    "\n",
    "def get_std(data_x, mean):\n",
    "    shape = data_x.shape\n",
    "    std = np.zeros((shape[1], shape[2]))\n",
    "    for j in range(shape[1]):\n",
    "        for k in range(shape[2]):\n",
    "            for i in range(shape[0]):\n",
    "                std[j][k] += (data_x[i][j][k][0] - mean[j][k])**2\n",
    "            std[j][k] = sqrt(std[j][k]/(shape[0]-1))\n",
    "    return std\n",
    "\n",
    "def extract_all_data(source, reshape, standardize):\n",
    "    train_imgs, train_vals = extract_all_helper(source, 'train', reshape)\n",
    "    test_imgs, test_vals = extract_all_helper(source, 'valid', reshape)\n",
    "    if standardize == True:\n",
    "        mean = get_mean(train_imgs)\n",
    "        std = get_std(train_imgs, mean)\n",
    "        train_imgs = (train_imgs - mean)/std\n",
    "        test_imgs = (test_imgs - mean)/std\n",
    "    return train_imgs, train_vals, test_imgs, test_vals\n",
    "\n",
    "def extract_helper(source, torv, kind, reshape):\n",
    "    os.chdir(source+'\\\\MURA-v1.1')\n",
    "    os.chdir(torv+'_specific_paths')\n",
    "    file = open(torv+'_image_paths_'+kind+'.csv')\n",
    "    return extract(source, file, reshape)\n",
    "\n",
    "def extract_all_helper(source, torv, reshape):\n",
    "    os.chdir(source+'\\\\MURA-v1.1')\n",
    "    file = open(torv+'_image_paths.csv')\n",
    "    return extract(source, file, reshape)\n",
    "    \n",
    "def extract(source, file, reshape):\n",
    "    readCSV = reader(file)\n",
    "    imgs = []\n",
    "    vals = []\n",
    "    for row in readCSV:\n",
    "        im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "        imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "        if 'positive' in row[0]:\n",
    "            vals.append(1)\n",
    "        else:\n",
    "            vals.append(0)\n",
    "    file.close()\n",
    "    imgs = np.array(imgs)\n",
    "    vals = np.array(vals)\n",
    "    imgs = np.expand_dims(imgs, axis = 3)\n",
    "    return imgs,vals\n",
    "\n",
    "class patient:\n",
    "    def __init__(self, imgs, vals, value):\n",
    "        self.imgs = imgs\n",
    "        self.vals = vals\n",
    "        self.value = value\n",
    "        \n",
    "def patient_code(path):\n",
    "    pos = path.find('patient')+7\n",
    "    return path[pos:pos+5]\n",
    "\n",
    "def patient_value(path):\n",
    "    if 'positive' in path:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def extract_all_data_patients(source, reshape, standardize):\n",
    "    train_patients = []\n",
    "    test_patients = []\n",
    "    for kind in ['elbow', 'finger', 'forearm', 'hand', 'humerus', 'shoulder', 'wrist']:\n",
    "        temp_train_patients, temp_test_patients = extract_data_patients(source, kind, reshape, False)\n",
    "        train_patients += temp_train_patients\n",
    "        test_patients += temp_test_patients\n",
    "    if standardize == True:\n",
    "        train_imgs = np.array([])\n",
    "        for p in train_patients:\n",
    "            train_imgs = np.concatenate(train_imgs, p.imgs)\n",
    "        mean = get_mean(train_imgs)\n",
    "        std = get_std(train_imgs, mean)\n",
    "        for p in train_patients:\n",
    "            p.imgs = (p.imgs - mean)/std\n",
    "        for p in test_patients:\n",
    "            p.imgs = (p.imgs - mean)/std\n",
    "    return train_patients, test_patients        \n",
    "        \n",
    "def extract_data_patients(source, kind, reshape, standardize):\n",
    "    train_patients = extract_helper_patients(source, 'train', kind, reshape)\n",
    "    test_patients  = extract_helper_patients(source, 'valid',  kind, reshape)\n",
    "    if standardize == True:\n",
    "        train_imgs = np.array([])\n",
    "        for p in train_patients:\n",
    "            train_imgs = np.concatenate(train_imgs, p.imgs)\n",
    "        mean = get_mean(train_imgs)\n",
    "        std = get_std(train_imgs, mean)\n",
    "        for p in train_patients:\n",
    "            p.imgs = (p.imgs - mean)/std\n",
    "        for p in test_patients:\n",
    "            p.imgs = (p.imgs - mean)/std\n",
    "    return train_patients, test_patients\n",
    "    \n",
    "def extract_helper_patients(source, torv, kind, reshape):\n",
    "    os.chdir(source+'\\\\MURA-v1.1')\n",
    "    os.chdir(torv+'_specific_paths')\n",
    "    file = open(torv+'_image_paths_'+kind+'.csv')\n",
    "    return extract_patients(source, file, reshape)\n",
    "\n",
    "def extract_patients(source, file, reshape):\n",
    "    patients = []\n",
    "    readCSV = reader(file)\n",
    "    imgs = []\n",
    "    vals = []\n",
    "    \n",
    "    row = next(readCSV)\n",
    "    prev_patient = patient_code(row[0])\n",
    "    vals.append(patient_value(row[0]))\n",
    "    im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "    imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "    \n",
    "    for row in readCSV:\n",
    "        curr_patient = patient_code(row[0])\n",
    "        if curr_patient == prev_patient:\n",
    "            vals.append(patient_value(row[0]))\n",
    "            im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "            imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "                \n",
    "        else:\n",
    "            imgs = np.array(imgs)\n",
    "            imgs = np.expand_dims(imgs, axis=3)\n",
    "            vals = np.array(vals)\n",
    "            patients.append(patient(imgs, vals, vals[0]))\n",
    "            imgs = []\n",
    "            vals = []\n",
    "            prev_patient = curr_patient\n",
    "            vals.append(patient_value(row[0]))\n",
    "            im = cv2.imread(source+'\\\\'+row[0], cv2.IMREAD_GRAYSCALE)\n",
    "            imgs.append(np.array(cv2.resize(im,reshape)))\n",
    "                \n",
    "    file.close()\n",
    "    imgs = np.array(imgs)\n",
    "    imgs = np.expand_dims(imgs, axis=3)\n",
    "    vals = np.array(vals)\n",
    "    patients.append(patient(imgs, vals, vals[0])) \n",
    "\n",
    "    return patients  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_validation(model, data_x, data_y, batch_size, number_of_epochs, class_weights, proportion = 0.8):\n",
    "    proportion = int(len(data_y)*proportion)\n",
    "    train_x, train_y = shuffler(data_x[:proportion], data_y[:proportion])\n",
    "    valid_x, valid_y = shuffler(data_x[proportion:], data_y[proportion:])\n",
    "    score = 0\n",
    "    if class_weights == True:\n",
    "        model_copy = copy_model(model)\n",
    "        model_copy.fit(train_x, train_y, batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(train_y))\n",
    "        score = conf_matrix(model_copy, valid_x, valid_y)\n",
    "    else:\n",
    "        model.fit(train_x, train_y, batch_size = batch_size, epochs = number_of_epochs)\n",
    "        score = conf_matrix(model, valid_x, valid_y)\n",
    "    if class_weights == True:\n",
    "        model.fit(data_x, data_y, batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(data_y))\n",
    "    else:\n",
    "        model.fit(valid_x, valid_y, batch_size = batch_size, epochs = number_of_epochs)\n",
    "    return score, model\n",
    "\n",
    "def k_fold_cross_validation(k, model, data_x, data_y, batch_size, number_of_epochs, class_weights):\n",
    "    data_x, data_y = shuffler(data_x, data_y)\n",
    "    folds_x = []\n",
    "    folds_y = []\n",
    "    l = len(data_y)\n",
    "    for i in range(k):\n",
    "        folds_x.append(data_x[(l//k)*i: (l//k)*(i+1)])\n",
    "        folds_y.append(data_y[(l//k)*i: (l//k)*(i+1)])\n",
    "    score = 0\n",
    "    for i in range(k):\n",
    "        model_copy = copy_model(model)\n",
    "        for j in range(k):\n",
    "            if j!=i:\n",
    "                if class_weights == True:\n",
    "                    model_copy.fit(folds_x[j],folds_y[j], batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(folds_y[j]))\n",
    "                else:\n",
    "                    model_copy.fit(folds_x[j],folds_y[j], batch_size = batch_size, epochs = number_of_epochs)\n",
    "        score += model_copy.evaluate(folds_x[i],folds_y[i])[1]\n",
    "    \n",
    "    if class_weights == True:\n",
    "        model.fit(data_x, data_y, batch_size = batch_size, epochs = number_of_epochs, class_weight = class_weight(data_y))\n",
    "    else:\n",
    "        model = model_copy\n",
    "        model.fit(folds_x[k-1],folds_y[k-1], batch_size = batch_size, epochs = number_of_epochs)\n",
    "    return score/k, model\n",
    "\n",
    "def shuffler(data_x, data_y):\n",
    "    p = np.random.permutation(len(data_y))\n",
    "    return (data_x[p], data_y[p])\n",
    "\n",
    "def conf_matrix(model, data_x, data_y): \n",
    "    y_pred = model.predict(data_x).flatten().tolist()\n",
    "    y_true = data_y.tolist()\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred[i] = round(y_pred[i])\n",
    "    return print_conf_matrix(y_true, y_pred)\n",
    "\n",
    "def patients_conf_matrix(model, test_patients): \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for p in test_patients:\n",
    "        y_true.append(p.value)\n",
    "        p_predict = round(np.mean(model.predict(p.imgs)))\n",
    "        y_pred.append(p_predict)\n",
    "    return print_conf_matrix(y_true, y_pred)\n",
    "    \n",
    "def print_conf_matrix(y_true, y_pred):\n",
    "    score = 0\n",
    "    tn, fp, fn, tp = 0, 0, 0, 0\n",
    "    l = len(y_true)\n",
    "    for i in range(l):\n",
    "        if y_pred[i] == 0 and y_true[i] == 0:\n",
    "            tn+= 1\n",
    "            score+= 1\n",
    "        elif y_pred[i] == 1 and y_true[i] == 0:\n",
    "            fp+= 1\n",
    "        elif y_pred[i] == 0 and y_true[i] == 1:\n",
    "            fn+= 1\n",
    "        else:\n",
    "            tp+= 1\n",
    "            score+= 1\n",
    "    score/= l\n",
    "    print('Accuracy: '+str(score))\n",
    "    print('     T       F')\n",
    "    print('P    '+str(tp)+' '*(8-len(str(tp)))+str(fp))\n",
    "    print('N    '+str(tn)+' '*(8-len(str(tn)))+str(fn))\n",
    "    return score\n",
    "\n",
    "def save_model(source, model, model_name):\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\models')\n",
    "    model.save(model_name+'.h5')\n",
    "    \n",
    "def load_model(source, model_name):\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\models')\n",
    "    return models.load_model(model_name+'.h5')\n",
    "\n",
    "def copy_model(model):\n",
    "    model_copy = models.clone_model(model)\n",
    "    model_copy.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model_copy\n",
    "\n",
    "def class_weight(data_y):\n",
    "    positive = np.sum(data_y)\n",
    "    negative = np.size(data_y) - positive\n",
    "    return {0 : 1 + positive/negative, 1: 1 + negative/positive}\n",
    "\n",
    "def heatmaps(source, kind, reshape, model, last_conv_index, model_name = None, mean = None, std =  None): \n",
    "    image_folder_path = source+'\\\\MURA-v1.1\\\\heatmaps\\\\' + kind + '\\\\images'\n",
    "    for image_name in os.listdir(image_folder_path):\n",
    "        heatmap(source, image_name, kind, reshape, model, last_conv_index, model_name, mean, std)\n",
    "\n",
    "def heatmap(source, image_name, kind, reshape, model, last_conv_index, model_name = None, mean = None, std =  None): # image_name must include extension .png\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\heatmaps\\\\'+kind+'\\\\images')\n",
    "    image = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, reshape)\n",
    "    image = np.expand_dims(image, axis = 2)\n",
    "    if (mean, std) != (None, None):\n",
    "        image = (image - mean)/std\n",
    "    pred = round(model.predict(np.array([image])).flatten().tolist()[0])\n",
    "    print('\\''+image_name+'\\''+' predicted to be ', end = '')\n",
    "    if pred == 0:\n",
    "        print('negative')\n",
    "    else:\n",
    "        print('positive')\n",
    "\n",
    "    model_output = model.output\n",
    "    conv_layer = model.get_layer(index = last_conv_index) # indexed from 0\n",
    "    grads = K.gradients(model_output, conv_layer.output)[0]\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    iterate = K.function([model.input], [pooled_grads, conv_layer.output[0]])\n",
    "    pooled_grads_val, conv_layer_output_val = iterate(np.array([image]))\n",
    "    for i in range(conv_layer_output_val.shape[2]):\n",
    "        conv_layer_output_val[:, :, i]*= pooled_grads_val[i]\n",
    "    \n",
    "    heatmap = np.mean(conv_layer_output_val, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap/= np.max(heatmap)\n",
    "    image = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    heatmap_applied = heatmap * 0.5 + image\n",
    "    os.chdir(source+'\\\\MURA-v1.1\\\\heatmaps\\\\'+kind+'\\\\heatmaps')\n",
    "    image_name = image_name[:-4]\n",
    "    if model_name != None:\n",
    "        cv2.imwrite(model_name +'_'+ image_name +'_heatmap.png', heatmap)\n",
    "        cv2.imwrite(model_name +'_'+ image_name +'_heatmap_applied.png', heatmap_applied)\n",
    "    else:\n",
    "        cv2.imwrite(image_name + 'heatmap.png', heatmap)\n",
    "        cv2.imwrite(image_name + '_heatmap_applied.png', heatmap_applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'C:\\\\Users\\\\Admin\\\\Desktop\\\\python' # depends on where you saved MURA\n",
    "reshape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: how to extract data\n",
    "train_x, train_y, test_x, test_y = extract_data(source ,'elbow', reshape, False)\n",
    "train_x, train_y = shuffler(train_x, train_y)\n",
    "test_x, test_y = shuffler(test_x, test_y)\n",
    "train_patients, test_patients = extract_data_patients(source ,'elbow', reshape, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), activation='relu', input_shape=(224,224,1), padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(2, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(4, (5, 5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(4, (5, 5), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(8, (7, 7), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "sgd = SGD(momentum = 0.01, nesterov = True) # sgd version, previous one uses adam\n",
    "model.compile(loss='binary_crossentropy', optimizer= sgd, metrics=['accuracy'])\n",
    "\n",
    "save_model(source, model, 'conv3sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4931/4931 [==============================] - 63s 13ms/sample - loss: 0.7033 - acc: 0.5573 2s - loss:\n",
      "Epoch 2/30\n",
      "4931/4931 [==============================] - 63s 13ms/sample - loss: 0.6932 - acc: 0.5707\n",
      "Epoch 3/30\n",
      "4931/4931 [==============================] - 56s 11ms/sample - loss: 0.6915 - acc: 0.5733\n",
      "Epoch 4/30\n",
      "4931/4931 [==============================] - 56s 11ms/sample - loss: 0.6918 - acc: 0.5257\n",
      "Epoch 5/30\n",
      "4931/4931 [==============================] - 55s 11ms/sample - loss: 0.6919 - acc: 0.5358\n",
      "Epoch 6/30\n",
      "4931/4931 [==============================] - 58s 12ms/sample - loss: 0.6902 - acc: 0.5599\n",
      "Epoch 7/30\n",
      "4931/4931 [==============================] - 54s 11ms/sample - loss: 0.6892 - acc: 0.5575\n",
      "Epoch 8/30\n",
      "4931/4931 [==============================] - 55s 11ms/sample - loss: 0.6896 - acc: 0.5328\n",
      "Epoch 9/30\n",
      "4931/4931 [==============================] - 56s 11ms/sample - loss: 0.6889 - acc: 0.5348\n",
      "Epoch 10/30\n",
      "4931/4931 [==============================] - 60s 12ms/sample - loss: 0.6880 - acc: 0.5622\n",
      "Epoch 11/30\n",
      "4931/4931 [==============================] - 60s 12ms/sample - loss: 0.6886 - acc: 0.5273\n",
      "Epoch 12/30\n",
      "4931/4931 [==============================] - 62s 13ms/sample - loss: 0.6860 - acc: 0.5352\n",
      "Epoch 13/30\n",
      "4931/4931 [==============================] - 62s 13ms/sample - loss: 0.6867 - acc: 0.5472s - \n",
      "Epoch 14/30\n",
      "4931/4931 [==============================] - 66s 13ms/sample - loss: 0.6880 - acc: 0.5291\n",
      "Epoch 15/30\n",
      "4931/4931 [==============================] - 61s 12ms/sample - loss: 0.6878 - acc: 0.5214\n",
      "Epoch 16/30\n",
      "4931/4931 [==============================] - 63s 13ms/sample - loss: 0.6859 - acc: 0.5323\n",
      "Epoch 17/30\n",
      "4931/4931 [==============================] - 62s 13ms/sample - loss: 0.6859 - acc: 0.5469\n",
      "Epoch 18/30\n",
      "4931/4931 [==============================] - 61s 12ms/sample - loss: 0.6833 - acc: 0.5078\n",
      "Epoch 19/30\n",
      "4931/4931 [==============================] - 67s 13ms/sample - loss: 0.6842 - acc: 0.5230s - loss: 0.6840 - acc\n",
      "Epoch 20/30\n",
      "4931/4931 [==============================] - 64s 13ms/sample - loss: 0.6859 - acc: 0.5198\n",
      "Epoch 21/30\n",
      "4931/4931 [==============================] - 63s 13ms/sample - loss: 0.6869 - acc: 0.5358\n",
      "Epoch 22/30\n",
      "4931/4931 [==============================] - 66s 13ms/sample - loss: 0.6844 - acc: 0.5248\n",
      "Epoch 23/30\n",
      "4931/4931 [==============================] - 72s 15ms/sample - loss: 0.6849 - acc: 0.5636\n",
      "Epoch 24/30\n",
      "4931/4931 [==============================] - 67s 14ms/sample - loss: 0.6825 - acc: 0.5423\n",
      "Epoch 25/30\n",
      "4931/4931 [==============================] - 68s 14ms/sample - loss: 0.6839 - acc: 0.5504\n",
      "Epoch 26/30\n",
      "4931/4931 [==============================] - 70s 14ms/sample - loss: 0.6804 - acc: 0.5441\n",
      "Epoch 27/30\n",
      "4931/4931 [==============================] - 71s 14ms/sample - loss: 0.6850 - acc: 0.5323\n",
      "Epoch 28/30\n",
      "4931/4931 [==============================] - 73s 15ms/sample - loss: 0.6826 - acc: 0.5218\n",
      "Epoch 29/30\n",
      "4931/4931 [==============================] - 71s 14ms/sample - loss: 0.6821 - acc: 0.5425\n",
      "Epoch 30/30\n",
      "4931/4931 [==============================] - 66s 13ms/sample - loss: 0.6838 - acc: 0.5328\n",
      "Accuracy: 0.5634408602150538\n",
      "     T       F\n",
      "P    175     148\n",
      "N    87      55\n",
      "Accuracy: 0.506578947368421\n",
      "     T       F\n",
      "P    40      50\n",
      "N    37      25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.506578947368421"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size = 8, epochs = 30, class_weight = class_weight(train_y))\n",
    "save_model(source, model, 'conv3_sgd_224_elbow_30epochs')\n",
    "conf_matrix(model, test_x, test_y)\n",
    "patients_conf_matrix(model, test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'elbow_train_negative1.png' predicted to be positive\n",
      "'elbow_train_negative10.png' predicted to be positive\n",
      "'elbow_train_negative11.png' predicted to be positive\n",
      "'elbow_train_negative12.png' predicted to be positive\n",
      "'elbow_train_negative13.png' predicted to be negative\n",
      "'elbow_train_negative14.png' predicted to be negative\n",
      "'elbow_train_negative15.png' predicted to be positive\n",
      "'elbow_train_negative16.png' predicted to be positive\n",
      "'elbow_train_negative17.png' predicted to be positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:135: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'elbow_train_negative18.png' predicted to be negative\n",
      "'elbow_train_negative19.png' predicted to be positive\n",
      "'elbow_train_negative2.png' predicted to be negative\n",
      "'elbow_train_negative20.png' predicted to be positive\n",
      "'elbow_train_negative21.png' predicted to be positive\n",
      "'elbow_train_negative22.png' predicted to be positive\n",
      "'elbow_train_negative23.png' predicted to be positive\n",
      "'elbow_train_negative24.png' predicted to be negative\n",
      "'elbow_train_negative25.png' predicted to be positive\n",
      "'elbow_train_negative26.png' predicted to be positive\n",
      "'elbow_train_negative27.png' predicted to be positive\n",
      "'elbow_train_negative28.png' predicted to be positive\n",
      "'elbow_train_negative29.png' predicted to be positive\n",
      "'elbow_train_negative3.png' predicted to be negative\n",
      "'elbow_train_negative30.png' predicted to be negative\n",
      "'elbow_train_negative31.png' predicted to be positive\n",
      "'elbow_train_negative32.png' predicted to be positive\n",
      "'elbow_train_negative33.png' predicted to be negative\n",
      "'elbow_train_negative34.png' predicted to be positive\n",
      "'elbow_train_negative35.png' predicted to be negative\n",
      "'elbow_train_negative36.png' predicted to be positive\n",
      "'elbow_train_negative37.png' predicted to be positive\n",
      "'elbow_train_negative38.png' predicted to be positive\n",
      "'elbow_train_negative39.png' predicted to be positive\n",
      "'elbow_train_negative4.png' predicted to be positive\n",
      "'elbow_train_negative40.png' predicted to be positive\n",
      "'elbow_train_negative5.png' predicted to be positive\n",
      "'elbow_train_negative6.png' predicted to be positive\n",
      "'elbow_train_negative7.png' predicted to be positive\n",
      "'elbow_train_negative8.png' predicted to be positive\n",
      "'elbow_train_negative9.png' predicted to be positive\n",
      "'elbow_train_positive1.png' predicted to be positive\n",
      "'elbow_train_positive10.png' predicted to be positive\n",
      "'elbow_train_positive11.png' predicted to be positive\n",
      "'elbow_train_positive12.png' predicted to be negative\n",
      "'elbow_train_positive13.png' predicted to be positive\n",
      "'elbow_train_positive14.png' predicted to be positive\n",
      "'elbow_train_positive15.png' predicted to be positive\n",
      "'elbow_train_positive16.png' predicted to be positive\n",
      "'elbow_train_positive17.png' predicted to be positive\n",
      "'elbow_train_positive18.png' predicted to be positive\n",
      "'elbow_train_positive19.png' predicted to be negative\n",
      "'elbow_train_positive2.png' predicted to be positive\n",
      "'elbow_train_positive20.png' predicted to be positive\n",
      "'elbow_train_positive21.png' predicted to be positive\n",
      "'elbow_train_positive22.png' predicted to be positive\n",
      "'elbow_train_positive23.png' predicted to be negative\n",
      "'elbow_train_positive24.png' predicted to be positive\n",
      "'elbow_train_positive25.png' predicted to be negative\n",
      "'elbow_train_positive26.png' predicted to be negative\n",
      "'elbow_train_positive27.png' predicted to be positive\n",
      "'elbow_train_positive28.png' predicted to be positive\n",
      "'elbow_train_positive29.png' predicted to be positive\n",
      "'elbow_train_positive3.png' predicted to be positive\n",
      "'elbow_train_positive30.png' predicted to be positive\n",
      "'elbow_train_positive31.png' predicted to be positive\n",
      "'elbow_train_positive32.png' predicted to be positive\n",
      "'elbow_train_positive33.png' predicted to be positive\n",
      "'elbow_train_positive34.png' predicted to be positive\n",
      "'elbow_train_positive35.png' predicted to be negative\n",
      "'elbow_train_positive36.png' predicted to be positive\n",
      "'elbow_train_positive37.png' predicted to be negative\n",
      "'elbow_train_positive38.png' predicted to be positive\n",
      "'elbow_train_positive39.png' predicted to be positive\n",
      "'elbow_train_positive4.png' predicted to be positive\n",
      "'elbow_train_positive40.png' predicted to be positive\n",
      "'elbow_train_positive5.png' predicted to be positive\n",
      "'elbow_train_positive6.png' predicted to be positive\n",
      "'elbow_train_positive7.png' predicted to be positive\n",
      "'elbow_train_positive8.png' predicted to be positive\n",
      "'elbow_train_positive9.png' predicted to be positive\n",
      "'elbow_valid_negative1.png' predicted to be positive\n",
      "'elbow_valid_negative10.png' predicted to be negative\n",
      "'elbow_valid_negative100.png' predicted to be positive\n",
      "'elbow_valid_negative11.png' predicted to be positive\n",
      "'elbow_valid_negative12.png' predicted to be positive\n",
      "'elbow_valid_negative13.png' predicted to be negative\n",
      "'elbow_valid_negative14.png' predicted to be positive\n",
      "'elbow_valid_negative15.png' predicted to be positive\n",
      "'elbow_valid_negative16.png' predicted to be negative\n",
      "'elbow_valid_negative17.png' predicted to be positive\n",
      "'elbow_valid_negative18.png' predicted to be positive\n",
      "'elbow_valid_negative19.png' predicted to be negative\n",
      "'elbow_valid_negative2.png' predicted to be positive\n",
      "'elbow_valid_negative20.png' predicted to be positive\n",
      "'elbow_valid_negative21.png' predicted to be positive\n",
      "'elbow_valid_negative22.png' predicted to be positive\n",
      "'elbow_valid_negative23.png' predicted to be negative\n",
      "'elbow_valid_negative24.png' predicted to be positive\n",
      "'elbow_valid_negative25.png' predicted to be positive\n",
      "'elbow_valid_negative26.png' predicted to be positive\n",
      "'elbow_valid_negative27.png' predicted to be negative\n",
      "'elbow_valid_negative28.png' predicted to be negative\n",
      "'elbow_valid_negative29.png' predicted to be positive\n",
      "'elbow_valid_negative3.png' predicted to be negative\n",
      "'elbow_valid_negative30.png' predicted to be positive\n",
      "'elbow_valid_negative31.png' predicted to be negative\n",
      "'elbow_valid_negative32.png' predicted to be positive\n",
      "'elbow_valid_negative33.png' predicted to be positive\n",
      "'elbow_valid_negative34.png' predicted to be negative\n",
      "'elbow_valid_negative35.png' predicted to be negative\n",
      "'elbow_valid_negative36.png' predicted to be positive\n",
      "'elbow_valid_negative37.png' predicted to be positive\n",
      "'elbow_valid_negative38.png' predicted to be negative\n",
      "'elbow_valid_negative39.png' predicted to be negative\n",
      "'elbow_valid_negative4.png' predicted to be negative\n",
      "'elbow_valid_negative40.png' predicted to be positive\n",
      "'elbow_valid_negative41.png' predicted to be positive\n",
      "'elbow_valid_negative42.png' predicted to be positive\n",
      "'elbow_valid_negative43.png' predicted to be negative\n",
      "'elbow_valid_negative44.png' predicted to be negative\n",
      "'elbow_valid_negative45.png' predicted to be negative\n",
      "'elbow_valid_negative46.png' predicted to be positive\n",
      "'elbow_valid_negative47.png' predicted to be negative\n",
      "'elbow_valid_negative48.png' predicted to be negative\n",
      "'elbow_valid_negative49.png' predicted to be negative\n",
      "'elbow_valid_negative5.png' predicted to be negative\n",
      "'elbow_valid_negative50.png' predicted to be positive\n",
      "'elbow_valid_negative51.png' predicted to be negative\n",
      "'elbow_valid_negative52.png' predicted to be positive\n",
      "'elbow_valid_negative53.png' predicted to be positive\n",
      "'elbow_valid_negative54.png' predicted to be positive\n",
      "'elbow_valid_negative55.png' predicted to be negative\n",
      "'elbow_valid_negative56.png' predicted to be positive\n",
      "'elbow_valid_negative57.png' predicted to be positive\n",
      "'elbow_valid_negative58.png' predicted to be negative\n",
      "'elbow_valid_negative59.png' predicted to be positive\n",
      "'elbow_valid_negative6.png' predicted to be positive\n",
      "'elbow_valid_negative60.png' predicted to be negative\n",
      "'elbow_valid_negative61.png' predicted to be negative\n",
      "'elbow_valid_negative62.png' predicted to be positive\n",
      "'elbow_valid_negative63.png' predicted to be positive\n",
      "'elbow_valid_negative64.png' predicted to be positive\n",
      "'elbow_valid_negative65.png' predicted to be negative\n",
      "'elbow_valid_negative66.png' predicted to be negative\n",
      "'elbow_valid_negative67.png' predicted to be positive\n",
      "'elbow_valid_negative68.png' predicted to be positive\n",
      "'elbow_valid_negative69.png' predicted to be positive\n",
      "'elbow_valid_negative7.png' predicted to be positive\n",
      "'elbow_valid_negative70.png' predicted to be positive\n",
      "'elbow_valid_negative71.png' predicted to be negative\n",
      "'elbow_valid_negative72.png' predicted to be positive\n",
      "'elbow_valid_negative73.png' predicted to be positive\n",
      "'elbow_valid_negative74.png' predicted to be negative\n",
      "'elbow_valid_negative75.png' predicted to be positive\n",
      "'elbow_valid_negative76.png' predicted to be negative\n",
      "'elbow_valid_negative77.png' predicted to be positive\n",
      "'elbow_valid_negative78.png' predicted to be positive\n",
      "'elbow_valid_negative79.png' predicted to be positive\n",
      "'elbow_valid_negative8.png' predicted to be negative\n",
      "'elbow_valid_negative80.png' predicted to be positive\n",
      "'elbow_valid_negative81.png' predicted to be negative\n",
      "'elbow_valid_negative82.png' predicted to be negative\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'elbow_valid_negative83.png' predicted to be positive\n",
      "'elbow_valid_negative84.png' predicted to be positive\n",
      "'elbow_valid_negative85.png' predicted to be positive\n",
      "'elbow_valid_negative86.png' predicted to be positive\n",
      "'elbow_valid_negative87.png' predicted to be negative\n",
      "'elbow_valid_negative88.png' predicted to be positive\n",
      "'elbow_valid_negative89.png' predicted to be positive\n",
      "'elbow_valid_negative9.png' predicted to be negative\n",
      "'elbow_valid_negative90.png' predicted to be positive\n",
      "'elbow_valid_negative91.png' predicted to be positive\n",
      "'elbow_valid_negative92.png' predicted to be negative\n",
      "'elbow_valid_negative93.png' predicted to be negative\n",
      "'elbow_valid_negative94.png' predicted to be negative\n",
      "'elbow_valid_negative95.png' predicted to be positive\n",
      "'elbow_valid_negative96.png' predicted to be positive\n",
      "'elbow_valid_negative97.png' predicted to be negative\n",
      "'elbow_valid_negative98.png' predicted to be positive\n",
      "'elbow_valid_negative99.png' predicted to be positive\n",
      "'elbow_valid_positive1.png' predicted to be positive\n",
      "'elbow_valid_positive10.png' predicted to be positive\n",
      "'elbow_valid_positive100.png' predicted to be positive\n",
      "'elbow_valid_positive11.png' predicted to be positive\n",
      "'elbow_valid_positive12.png' predicted to be positive\n",
      "'elbow_valid_positive13.png' predicted to be positive\n",
      "'elbow_valid_positive14.png' predicted to be negative\n",
      "'elbow_valid_positive15.png' predicted to be positive\n",
      "'elbow_valid_positive16.png' predicted to be positive\n",
      "'elbow_valid_positive17.png' predicted to be positive\n",
      "'elbow_valid_positive18.png' predicted to be negative\n",
      "'elbow_valid_positive19.png' predicted to be positive\n",
      "'elbow_valid_positive2.png' predicted to be positive\n",
      "'elbow_valid_positive20.png' predicted to be negative\n",
      "'elbow_valid_positive21.png' predicted to be negative\n",
      "'elbow_valid_positive22.png' predicted to be positive\n",
      "'elbow_valid_positive23.png' predicted to be positive\n",
      "'elbow_valid_positive24.png' predicted to be positive\n",
      "'elbow_valid_positive25.png' predicted to be negative\n",
      "'elbow_valid_positive26.png' predicted to be positive\n",
      "'elbow_valid_positive27.png' predicted to be positive\n",
      "'elbow_valid_positive28.png' predicted to be negative\n",
      "'elbow_valid_positive29.png' predicted to be positive\n",
      "'elbow_valid_positive3.png' predicted to be negative\n",
      "'elbow_valid_positive30.png' predicted to be negative\n",
      "'elbow_valid_positive31.png' predicted to be positive\n",
      "'elbow_valid_positive32.png' predicted to be positive\n",
      "'elbow_valid_positive33.png' predicted to be positive\n",
      "'elbow_valid_positive34.png' predicted to be negative\n",
      "'elbow_valid_positive35.png' predicted to be positive\n",
      "'elbow_valid_positive36.png' predicted to be negative\n",
      "'elbow_valid_positive37.png' predicted to be positive\n",
      "'elbow_valid_positive38.png' predicted to be positive\n",
      "'elbow_valid_positive39.png' predicted to be negative\n",
      "'elbow_valid_positive4.png' predicted to be positive\n",
      "'elbow_valid_positive40.png' predicted to be positive\n",
      "'elbow_valid_positive41.png' predicted to be positive\n",
      "'elbow_valid_positive42.png' predicted to be positive\n",
      "'elbow_valid_positive43.png' predicted to be negative\n",
      "'elbow_valid_positive44.png' predicted to be positive\n",
      "'elbow_valid_positive45.png' predicted to be positive\n",
      "'elbow_valid_positive46.png' predicted to be positive\n",
      "'elbow_valid_positive47.png' predicted to be positive\n",
      "'elbow_valid_positive48.png' predicted to be positive\n",
      "'elbow_valid_positive49.png' predicted to be positive\n",
      "'elbow_valid_positive5.png' predicted to be negative\n",
      "'elbow_valid_positive50.png' predicted to be positive\n",
      "'elbow_valid_positive51.png' predicted to be positive\n",
      "'elbow_valid_positive52.png' predicted to be positive\n",
      "'elbow_valid_positive53.png' predicted to be positive\n",
      "'elbow_valid_positive54.png' predicted to be negative\n",
      "'elbow_valid_positive55.png' predicted to be positive\n",
      "'elbow_valid_positive56.png' predicted to be positive\n",
      "'elbow_valid_positive57.png' predicted to be positive\n",
      "'elbow_valid_positive58.png' predicted to be positive\n",
      "'elbow_valid_positive59.png' predicted to be negative\n",
      "'elbow_valid_positive6.png' predicted to be positive\n",
      "'elbow_valid_positive60.png' predicted to be positive\n",
      "'elbow_valid_positive61.png' predicted to be positive\n",
      "'elbow_valid_positive62.png' predicted to be positive\n",
      "'elbow_valid_positive63.png' predicted to be negative\n",
      "'elbow_valid_positive64.png' predicted to be negative\n",
      "'elbow_valid_positive65.png' predicted to be negative\n",
      "'elbow_valid_positive66.png' predicted to be negative\n",
      "'elbow_valid_positive67.png' predicted to be positive\n",
      "'elbow_valid_positive68.png' predicted to be positive\n",
      "'elbow_valid_positive69.png' predicted to be positive\n",
      "'elbow_valid_positive7.png' predicted to be negative\n",
      "'elbow_valid_positive70.png' predicted to be positive\n",
      "'elbow_valid_positive71.png' predicted to be positive\n",
      "'elbow_valid_positive72.png' predicted to be positive\n",
      "'elbow_valid_positive73.png' predicted to be positive\n",
      "'elbow_valid_positive74.png' predicted to be positive\n",
      "'elbow_valid_positive75.png' predicted to be positive\n",
      "'elbow_valid_positive76.png' predicted to be positive\n",
      "'elbow_valid_positive77.png' predicted to be positive\n",
      "'elbow_valid_positive78.png' predicted to be positive\n",
      "'elbow_valid_positive79.png' predicted to be positive\n",
      "'elbow_valid_positive8.png' predicted to be positive\n",
      "'elbow_valid_positive80.png' predicted to be negative\n",
      "'elbow_valid_positive81.png' predicted to be negative\n",
      "'elbow_valid_positive82.png' predicted to be positive\n",
      "'elbow_valid_positive83.png' predicted to be positive\n",
      "'elbow_valid_positive84.png' predicted to be positive\n",
      "'elbow_valid_positive85.png' predicted to be positive\n",
      "'elbow_valid_positive86.png' predicted to be negative\n",
      "'elbow_valid_positive87.png' predicted to be positive\n",
      "'elbow_valid_positive88.png' predicted to be positive\n",
      "'elbow_valid_positive89.png' predicted to be positive\n",
      "'elbow_valid_positive9.png' predicted to be negative\n",
      "'elbow_valid_positive90.png' predicted to be negative\n",
      "'elbow_valid_positive91.png' predicted to be positive\n",
      "'elbow_valid_positive92.png' predicted to be negative\n",
      "'elbow_valid_positive93.png' predicted to be negative\n",
      "'elbow_valid_positive94.png' predicted to be positive\n",
      "'elbow_valid_positive95.png' predicted to be positive\n",
      "'elbow_valid_positive96.png' predicted to be negative\n",
      "'elbow_valid_positive97.png' predicted to be positive\n",
      "'elbow_valid_positive98.png' predicted to be positive\n",
      "'elbow_valid_positive99.png' predicted to be positive\n",
      "'train_negative1.png' predicted to be negative\n",
      "'train_negative10.png' predicted to be negative\n",
      "'train_negative11.png' predicted to be positive\n",
      "'train_negative12.png' predicted to be positive\n",
      "'train_negative13.png' predicted to be positive\n",
      "'train_negative14.png' predicted to be positive\n",
      "'train_negative15.png' predicted to be negative\n",
      "'train_negative16.png' predicted to be negative\n",
      "'train_negative17.png' predicted to be positive\n",
      "'train_negative18.png' predicted to be positive\n",
      "'train_negative19.png' predicted to be positive\n",
      "'train_negative2.png' predicted to be positive\n",
      "'train_negative20.png' predicted to be negative\n",
      "'train_negative21.png' predicted to be negative\n",
      "'train_negative22.png' predicted to be positive\n",
      "'train_negative23.png' predicted to be negative\n",
      "'train_negative24.png' predicted to be negative\n",
      "'train_negative25.png' predicted to be positive\n",
      "'train_negative26.png' predicted to be negative\n",
      "'train_negative27.png' predicted to be positive\n",
      "'train_negative28.png' predicted to be positive\n",
      "'train_negative29.png' predicted to be positive\n",
      "'train_negative3.png' predicted to be positive\n",
      "'train_negative30.png' predicted to be negative\n",
      "'train_negative4.png' predicted to be negative\n",
      "'train_negative5.png' predicted to be positive\n",
      "'train_negative6.png' predicted to be negative\n",
      "'train_negative7.png' predicted to be negative\n",
      "'train_negative8.png' predicted to be positive\n",
      "'train_negative9.png' predicted to be positive\n",
      "'train_positive1.png' predicted to be positive\n",
      "'train_positive10.png' predicted to be positive\n",
      "'train_positive11.png' predicted to be positive\n",
      "'train_positive12.png' predicted to be positive\n",
      "'train_positive13.png' predicted to be positive\n",
      "'train_positive14.png' predicted to be positive\n",
      "'train_positive15.png' predicted to be negative\n",
      "'train_positive16.png' predicted to be positive\n",
      "'train_positive17.png' predicted to be negative\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_positive18.png' predicted to be positive\n",
      "'train_positive19.png' predicted to be negative\n",
      "'train_positive2.png' predicted to be positive\n",
      "'train_positive20.png' predicted to be positive\n",
      "'train_positive21.png' predicted to be positive\n",
      "'train_positive22.png' predicted to be positive\n",
      "'train_positive23.png' predicted to be positive\n",
      "'train_positive24.png' predicted to be negative\n",
      "'train_positive25.png' predicted to be positive\n",
      "'train_positive26.png' predicted to be positive\n",
      "'train_positive27.png' predicted to be positive\n",
      "'train_positive28.png' predicted to be positive\n",
      "'train_positive29.png' predicted to be positive\n",
      "'train_positive3.png' predicted to be positive\n",
      "'train_positive30.png' predicted to be positive\n",
      "'train_positive4.png' predicted to be negative\n",
      "'train_positive5.png' predicted to be positive\n",
      "'train_positive6.png' predicted to be negative\n",
      "'train_positive7.png' predicted to be positive\n",
      "'train_positive8.png' predicted to be positive\n",
      "'train_positive9.png' predicted to be positive\n",
      "'valid_negative1.png' predicted to be positive\n",
      "'valid_negative10.png' predicted to be positive\n",
      "'valid_negative11.png' predicted to be positive\n",
      "'valid_negative12.png' predicted to be positive\n",
      "'valid_negative13.png' predicted to be negative\n",
      "'valid_negative14.png' predicted to be positive\n",
      "'valid_negative15.png' predicted to be positive\n",
      "'valid_negative16.png' predicted to be negative\n",
      "'valid_negative17.png' predicted to be negative\n",
      "'valid_negative18.png' predicted to be positive\n",
      "'valid_negative19.png' predicted to be positive\n",
      "'valid_negative2.png' predicted to be negative\n",
      "'valid_negative20.png' predicted to be negative\n",
      "'valid_negative21.png' predicted to be negative\n",
      "'valid_negative22.png' predicted to be negative\n",
      "'valid_negative23.png' predicted to be positive\n",
      "'valid_negative24.png' predicted to be negative\n",
      "'valid_negative25.png' predicted to be negative\n",
      "'valid_negative26.png' predicted to be positive\n",
      "'valid_negative27.png' predicted to be positive\n",
      "'valid_negative28.png' predicted to be negative\n",
      "'valid_negative29.png' predicted to be positive\n",
      "'valid_negative3.png' predicted to be positive\n",
      "'valid_negative30.png' predicted to be positive\n",
      "'valid_negative4.png' predicted to be positive\n",
      "'valid_negative5.png' predicted to be positive\n",
      "'valid_negative6.png' predicted to be positive\n",
      "'valid_negative7.png' predicted to be positive\n",
      "'valid_negative8.png' predicted to be negative\n",
      "'valid_negative9.png' predicted to be negative\n",
      "'valid_positive1.png' predicted to be positive\n",
      "'valid_positive10.png' predicted to be positive\n",
      "'valid_positive11.png' predicted to be positive\n",
      "'valid_positive12.png' predicted to be negative\n",
      "'valid_positive13.png' predicted to be positive\n",
      "'valid_positive14.png' predicted to be positive\n",
      "'valid_positive15.png' predicted to be positive\n",
      "'valid_positive16.png' predicted to be positive\n",
      "'valid_positive17.png' predicted to be positive\n",
      "'valid_positive18.png' predicted to be positive\n",
      "'valid_positive19.png' predicted to be positive\n",
      "'valid_positive2.png' predicted to be positive\n",
      "'valid_positive20.png' predicted to be negative\n",
      "'valid_positive21.png' predicted to be positive\n",
      "'valid_positive22.png' predicted to be negative\n",
      "'valid_positive23.png' predicted to be negative\n",
      "'valid_positive24.png' predicted to be positive\n",
      "'valid_positive25.png' predicted to be positive\n",
      "'valid_positive26.png' predicted to be positive\n",
      "'valid_positive27.png' predicted to be positive\n",
      "'valid_positive28.png' predicted to be negative\n",
      "'valid_positive29.png' predicted to be positive\n",
      "'valid_positive3.png' predicted to be negative\n",
      "'valid_positive30.png' predicted to be negative\n",
      "'valid_positive4.png' predicted to be positive\n",
      "'valid_positive5.png' predicted to be negative\n",
      "'valid_positive6.png' predicted to be positive\n",
      "'valid_positive7.png' predicted to be positive\n",
      "'valid_positive8.png' predicted to be positive\n",
      "'valid_positive9.png' predicted to be positive\n"
     ]
    }
   ],
   "source": [
    "# Example: how to use models\n",
    "model = load_model(source, 'conv3_sgd_224_elbow_30epochs')\n",
    "heatmaps(source, 'elbow', (224,224), model, 12, 'conv3_sgd_224_elbow_30epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
